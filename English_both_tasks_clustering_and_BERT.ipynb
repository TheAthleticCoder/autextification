{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adade34bc77d4206967a36f2d5f6b5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2463cf7ba4054166b74231e8597ef74b",
              "IPY_MODEL_4882b7029f7b4c56a20356967bc35db2",
              "IPY_MODEL_41b698c6a3114a48885cc929aaeeafe8"
            ],
            "layout": "IPY_MODEL_7c4e2b3cfb9047188809278dc9eaa779"
          }
        },
        "2463cf7ba4054166b74231e8597ef74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d33a1e85a344a0d812c3a01c2a54c64",
            "placeholder": "​",
            "style": "IPY_MODEL_20bac9dcb1674b4b87cc0462329295d6",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "4882b7029f7b4c56a20356967bc35db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e9832714bee4f4a998ff71009ca8f63",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a31a56d204e4e35a038805b86dda742",
            "value": 213450
          }
        },
        "41b698c6a3114a48885cc929aaeeafe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c661f5183a38464b9c16007ff84f034b",
            "placeholder": "​",
            "style": "IPY_MODEL_baf123a82caa432b9ffe9337c772f444",
            "value": " 213k/213k [00:00&lt;00:00, 1.30MB/s]"
          }
        },
        "7c4e2b3cfb9047188809278dc9eaa779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d33a1e85a344a0d812c3a01c2a54c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20bac9dcb1674b4b87cc0462329295d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e9832714bee4f4a998ff71009ca8f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a31a56d204e4e35a038805b86dda742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c661f5183a38464b9c16007ff84f034b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf123a82caa432b9ffe9337c772f444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99388fa77b584e43b3597b9b3bfb4aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b864b76e0dd44fc7aa931fe96bf5515a",
              "IPY_MODEL_3f9f970b94ae48569357cb2eb26f5cfc",
              "IPY_MODEL_0eb6b3b4a43b4ccf8c48065407ef61a7"
            ],
            "layout": "IPY_MODEL_ee0cd75a4f434a3380240076dc863bb4"
          }
        },
        "b864b76e0dd44fc7aa931fe96bf5515a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_558ed9a0b27442178c393b1ba1f83bdc",
            "placeholder": "​",
            "style": "IPY_MODEL_2c408b21b199466789afd89b962751aa",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "3f9f970b94ae48569357cb2eb26f5cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c639bb3d8034bbaa4a10b8e56952bd6",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d1b78ff82854e7aae2e92fc94d2f040",
            "value": 29
          }
        },
        "0eb6b3b4a43b4ccf8c48065407ef61a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f735b7c059c4f5dabf9c22a8e8cc959",
            "placeholder": "​",
            "style": "IPY_MODEL_10dfb2967ebf404890170cbbdb0da5cb",
            "value": " 29.0/29.0 [00:00&lt;00:00, 2.17kB/s]"
          }
        },
        "ee0cd75a4f434a3380240076dc863bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558ed9a0b27442178c393b1ba1f83bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c408b21b199466789afd89b962751aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c639bb3d8034bbaa4a10b8e56952bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1b78ff82854e7aae2e92fc94d2f040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f735b7c059c4f5dabf9c22a8e8cc959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10dfb2967ebf404890170cbbdb0da5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02e058227b824962a9ac993a98ef2a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3c12cc35fdb4d409f181685ec5ec863",
              "IPY_MODEL_421cb1af5a574fbe92788ba25928ca91",
              "IPY_MODEL_45ab301f6a1c41f48a988609dfff5a11"
            ],
            "layout": "IPY_MODEL_5b4d9778031b409fb174e14881e735d9"
          }
        },
        "f3c12cc35fdb4d409f181685ec5ec863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ca38032aaf45d9a862c7d08e07061e",
            "placeholder": "​",
            "style": "IPY_MODEL_4f44b81404184ef388862343a64dd202",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "421cb1af5a574fbe92788ba25928ca91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f768375557db4010a0a2573f082cdcba",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b915fdf358294b4697d1b83b5942816f",
            "value": 570
          }
        },
        "45ab301f6a1c41f48a988609dfff5a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20dac367c7bb4d6b9b28c76bc3fc6595",
            "placeholder": "​",
            "style": "IPY_MODEL_4b4daad03d1646b387c44808037b4515",
            "value": " 570/570 [00:00&lt;00:00, 33.1kB/s]"
          }
        },
        "5b4d9778031b409fb174e14881e735d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ca38032aaf45d9a862c7d08e07061e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f44b81404184ef388862343a64dd202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f768375557db4010a0a2573f082cdcba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b915fdf358294b4697d1b83b5942816f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20dac367c7bb4d6b9b28c76bc3fc6595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b4daad03d1646b387c44808037b4515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccd15951297c474a87829f924a724dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7160a4d340042c99fd0a85b7b93b9e3",
              "IPY_MODEL_8e00aae567244df194c08196115eb2c2",
              "IPY_MODEL_f85970af5bad4574a9546c3959440f5d"
            ],
            "layout": "IPY_MODEL_ca857af941974903a370abcfd9ff1909"
          }
        },
        "a7160a4d340042c99fd0a85b7b93b9e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f7dd79b6744a77ae8e81afffb9e226",
            "placeholder": "​",
            "style": "IPY_MODEL_d457474fc4094396b73af5ae7140c9c6",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "8e00aae567244df194c08196115eb2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7744803bd2a42a4bf1483b4bd198be6",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d565a2c6a949f095d3b12765c9d30a",
            "value": 435779157
          }
        },
        "f85970af5bad4574a9546c3959440f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4132047bbd04270b0fc3bec21977c38",
            "placeholder": "​",
            "style": "IPY_MODEL_44ef7b7b626a45829ae6681aeba7a8ed",
            "value": " 436M/436M [00:01&lt;00:00, 274MB/s]"
          }
        },
        "ca857af941974903a370abcfd9ff1909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f7dd79b6744a77ae8e81afffb9e226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d457474fc4094396b73af5ae7140c9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7744803bd2a42a4bf1483b4bd198be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d565a2c6a949f095d3b12765c9d30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4132047bbd04270b0fc3bec21977c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ef7b7b626a45829ae6681aeba7a8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQFO-3Hr2c4Y",
        "outputId": "9091685b-4f15-4d1b-8c9e-be665f7fa89a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "94OpNyuGEK46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173a2195-a5fc-4117-86f0-7672fbf21d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast, BertTokenizer, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create train test and validation\n",
        "\n",
        "trainAmt = 0.7\n",
        "validationTestRatio = 0.5\n",
        "\n",
        "with open('/content/drive/MyDrive/Datasets/Autextification_datasets/subtask_1/en/train.tsv', 'r') as f:\n",
        "  allData = f.readlines()\n",
        "\n",
        "np.random.shuffle(allData)\n",
        "\n",
        "trainIdx = int(np.floor(len(allData) * trainAmt))\n",
        "valIdx = int(np.floor(len(allData) * (1 - trainAmt) * validationTestRatio) + trainIdx)"
      ],
      "metadata": {
        "id": "3WV3TvidFBPf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "labels = []\n",
        "\n",
        "for datum in tqdm(allData):\n",
        "  _, s, lbl = datum[:-1].split('\\t')\n",
        "  text.append(s)\n",
        "  labels.append(1 if lbl == 'generated' else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKWpsloczsMn",
        "outputId": "58489538-6e3c-4b00-a4bb-08c0531ed22a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33846/33846 [00:00<00:00, 450110.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id = []\n",
        "attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  '''\n",
        "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "  '''\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 90,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    do_lower_case = True\n",
        "    )\n",
        "\n",
        "for sample in tqdm(text):\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids']) \n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "adade34bc77d4206967a36f2d5f6b5eb",
            "2463cf7ba4054166b74231e8597ef74b",
            "4882b7029f7b4c56a20356967bc35db2",
            "41b698c6a3114a48885cc929aaeeafe8",
            "7c4e2b3cfb9047188809278dc9eaa779",
            "6d33a1e85a344a0d812c3a01c2a54c64",
            "20bac9dcb1674b4b87cc0462329295d6",
            "0e9832714bee4f4a998ff71009ca8f63",
            "3a31a56d204e4e35a038805b86dda742",
            "c661f5183a38464b9c16007ff84f034b",
            "baf123a82caa432b9ffe9337c772f444",
            "99388fa77b584e43b3597b9b3bfb4aea",
            "b864b76e0dd44fc7aa931fe96bf5515a",
            "3f9f970b94ae48569357cb2eb26f5cfc",
            "0eb6b3b4a43b4ccf8c48065407ef61a7",
            "ee0cd75a4f434a3380240076dc863bb4",
            "558ed9a0b27442178c393b1ba1f83bdc",
            "2c408b21b199466789afd89b962751aa",
            "7c639bb3d8034bbaa4a10b8e56952bd6",
            "9d1b78ff82854e7aae2e92fc94d2f040",
            "4f735b7c059c4f5dabf9c22a8e8cc959",
            "10dfb2967ebf404890170cbbdb0da5cb",
            "02e058227b824962a9ac993a98ef2a68",
            "f3c12cc35fdb4d409f181685ec5ec863",
            "421cb1af5a574fbe92788ba25928ca91",
            "45ab301f6a1c41f48a988609dfff5a11",
            "5b4d9778031b409fb174e14881e735d9",
            "83ca38032aaf45d9a862c7d08e07061e",
            "4f44b81404184ef388862343a64dd202",
            "f768375557db4010a0a2573f082cdcba",
            "b915fdf358294b4697d1b83b5942816f",
            "20dac367c7bb4d6b9b28c76bc3fc6595",
            "4b4daad03d1646b387c44808037b4515"
          ]
        },
        "id": "2uttb92FzhnI",
        "outputId": "c48e2920-e20e-4375-b22c-9fca02737d24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adade34bc77d4206967a36f2d5f6b5eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99388fa77b584e43b3597b9b3bfb4aea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02e058227b824962a9ac993a98ef2a68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/33846 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 33846/33846 [01:00<00:00, 563.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train val and test\n",
        "\n",
        "valntest_ratio = 0.3\n",
        "valtest_split = 0.5\n",
        "batch_size = 16\n",
        "\n",
        "# Indices of the train and validation splits stratified by labels\n",
        "train_idx, temp_idx = train_test_split(\n",
        "    np.arange(len(labels)),\n",
        "    test_size = valntest_ratio,\n",
        "    shuffle = True,\n",
        "    stratify = labels)\n",
        "\n",
        "val_idx, test_idx = train_test_split(\n",
        "    np.arange(len(labels[temp_idx])),\n",
        "    test_size = valtest_split,\n",
        "    shuffle = True,\n",
        "    stratify = labels[temp_idx])\n",
        "\n",
        "# Train and validation sets\n",
        "train_set = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          labels[train_idx])\n",
        "\n",
        "val_set = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        labels[val_idx])\n",
        "\n",
        "test_set = TensorDataset(token_id[test_idx], \n",
        "                        attention_masks[test_idx], \n",
        "                        labels[test_idx])\n",
        "\n",
        "\n",
        "# Prepare DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "            train_set,\n",
        "            sampler = RandomSampler(train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_set,\n",
        "            sampler = SequentialSampler(val_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            test_set,\n",
        "            sampler = SequentialSampler(test_set),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "nWE5tNEF1GoS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "seq_len = [len(i.split()) for i in text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "vdDW8gM3xj00",
        "outputId": "a4e7af88-05ce-40d9-8193-9f2d30a7756a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "metadata": {
        "id": "HUtPn983S038"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                              lr = 5e-5,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "lossFn = nn.CrossEntropyLoss()\n",
        "\n",
        "# model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "ccd15951297c474a87829f924a724dd8",
            "a7160a4d340042c99fd0a85b7b93b9e3",
            "8e00aae567244df194c08196115eb2c2",
            "f85970af5bad4574a9546c3959440f5d",
            "ca857af941974903a370abcfd9ff1909",
            "b4f7dd79b6744a77ae8e81afffb9e226",
            "d457474fc4094396b73af5ae7140c9c6",
            "c7744803bd2a42a4bf1483b4bd198be6",
            "e1d565a2c6a949f095d3b12765c9d30a",
            "e4132047bbd04270b0fc3bec21977c38",
            "44ef7b7b626a45829ae6681aeba7a8ed"
          ]
        },
        "id": "NxCyJf0L41ad",
        "outputId": "f5f5f8f3-c522-48a9-baa8-a6039559f2fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccd15951297c474a87829f924a724dd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train naive single BERT"
      ],
      "metadata": {
        "id": "LAErG9Uz2OD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "print(\"Set length: \", len(train_dataloader))\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    \n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    updator = 100\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if (step+1) % updator == 0:\n",
        "          print(\"Step: \", step)\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        # print(\"Logits: \", train_output.logits)\n",
        "        # print(\"Labels: \", b_labels)\n",
        "\n",
        "        cntLoss = lossFn(train_output.logits, b_labels)\n",
        "\n",
        "        cntLoss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += cntLoss\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "        # print(\"Loss: \", train_output.loss)\n",
        "        # print(\"My loss\", cntLoss)\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
      ],
      "metadata": {
        "id": "IrmupI6J4utl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune ensemble BERTs on subtask B\n",
        "- 6 BERTs, one for each label\n",
        "- Each one performs binary classification\n"
      ],
      "metadata": {
        "id": "1jP78BlS2T9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess subtask B data\n",
        "\n",
        "trainAmt = 0.7\n",
        "validationTestRatio = 0.5\n",
        "\n",
        "with open('/content/drive/MyDrive/Datasets/Autextification_datasets/subtask_2/en/train.tsv', 'r') as f:\n",
        "  allData = f.readlines()\n",
        "allData = allData[1:]\n",
        "\n",
        "np.random.shuffle(allData)\n",
        "\n",
        "trainIdx = int(np.floor(len(allData) * trainAmt))\n",
        "valIdx = int(np.floor(len(allData) * (1 - trainAmt) * validationTestRatio) + trainIdx)\n",
        "\n",
        "text = []\n",
        "labels = []\n",
        "\n",
        "letter2lbl = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}\n",
        "\n",
        "for datum in tqdm(allData):\n",
        "  _, s, letter = datum[:-1].split('\\t')\n",
        "  text.append(s)\n",
        "  labels.append(letter2lbl[letter])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUjG-WmN2bb0",
        "outputId": "36d88a67-bd0d-435e-eb5e-3efe025abfa0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 624278.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "\n",
        "token_id = []\n",
        "attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  '''\n",
        "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "  '''\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 90,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    do_lower_case = True\n",
        "    )\n",
        "\n",
        "for sample in tqdm(text):\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids']) \n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzx1E7btH5rr",
        "outputId": "18842dd3-65b8-4123-8711-6be8d52c8359"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/22416 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 22416/22416 [00:39<00:00, 566.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders\n",
        "# split into train val and test\n",
        "\n",
        "numModels = 6 # ONE FOR EACH CLASS\n",
        "\n",
        "valntest_ratio = 0.3\n",
        "valtest_split = 0.5\n",
        "batch_size = 16\n",
        "\n",
        "# Indices of the train and validation splits stratified by labels\n",
        "train_idx, temp_idx = train_test_split(\n",
        "    np.arange(len(labels)),\n",
        "    test_size = valntest_ratio,\n",
        "    shuffle = True,\n",
        "    stratify = labels)\n",
        "\n",
        "val_idx, test_idx = train_test_split(\n",
        "    np.arange(len(labels[temp_idx])),\n",
        "    test_size = valtest_split,\n",
        "    shuffle = True,\n",
        "    stratify = labels[temp_idx])\n",
        "\n",
        "\n",
        "# Train and validation sets\n",
        "train_sets = []\n",
        "val_sets = []\n",
        "test_sets = []\n",
        "\n",
        "train_dataloaders = []\n",
        "validation_dataloaders = []\n",
        "test_dataloaders = []\n",
        "\n",
        "a = 100\n",
        "b = 110\n",
        "\n",
        "print(\"OG   \", end='\\t')\n",
        "print(labels[a:b])\n",
        "\n",
        "# 6 class datasets\n",
        "six_class_train_set = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          labels[train_idx])\n",
        "\n",
        "six_class_val_set = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        labels[val_idx])\n",
        "\n",
        "six_class_test_set = TensorDataset(token_id[test_idx], \n",
        "                        attention_masks[test_idx], \n",
        "                        labels[test_idx])\n",
        "\n",
        "six_class_train_dataloader = DataLoader(\n",
        "              six_class_train_set,\n",
        "              sampler = RandomSampler(six_class_train_set),\n",
        "              batch_size = batch_size\n",
        "          )\n",
        "\n",
        "six_class_validation_dataloader = DataLoader(\n",
        "            six_class_val_set,\n",
        "            sampler = SequentialSampler(six_class_val_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "six_class_test_dataloader = DataLoader(\n",
        "            six_class_test_set,\n",
        "            sampler = SequentialSampler(six_class_test_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "# binary classification datasets\n",
        "for i in range(numModels):\n",
        "  # label reassignment: i -> 1, not i -> 0\n",
        "  reassignedLabels = torch.tensor(np.where(np.array(labels) == i, 1, 0))\n",
        "\n",
        "  print(\"LABEL %d\" % i, end='\\t')\n",
        "  print(reassignedLabels[a:b])\n",
        "  \n",
        "  train_sets.append(TensorDataset(token_id[train_idx], \n",
        "                            attention_masks[train_idx], \n",
        "                            reassignedLabels[train_idx]))\n",
        "\n",
        "  val_sets.append(TensorDataset(token_id[val_idx], \n",
        "                          attention_masks[val_idx], \n",
        "                          reassignedLabels[val_idx]))\n",
        "\n",
        "  test_sets.append(TensorDataset(token_id[test_idx], \n",
        "                          attention_masks[test_idx], \n",
        "                          reassignedLabels[test_idx]))\n",
        "\n",
        "\n",
        "  # Prepare DataLoader\n",
        "  train_dataloaders.append(DataLoader(\n",
        "              train_sets[i],\n",
        "              sampler = RandomSampler(train_sets[i]),\n",
        "              batch_size = batch_size\n",
        "          ))\n",
        "\n",
        "  validation_dataloaders.append(DataLoader(\n",
        "              val_sets[i],\n",
        "              sampler = SequentialSampler(val_sets[i]),\n",
        "              batch_size = batch_size\n",
        "          ))\n",
        "\n",
        "  test_dataloaders.append(DataLoader(\n",
        "              test_sets[i],\n",
        "              sampler = SequentialSampler(test_sets[i]),\n",
        "              batch_size = batch_size\n",
        "          ))\n",
        "  \n",
        "  print(\"counts: \", end='\\t')\n",
        "  counts = [0,0,0,0,0,0]\n",
        "  for el in tqdm(reassignedLabels):\n",
        "    counts[el] += 1\n",
        "  print(counts)\n",
        "\n",
        "  print(\"lens: \", len(train_dataloaders[i]), len(validation_dataloaders[i]), len(test_dataloaders[i]))\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "xOQVJmD5J6A3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc90e2b-c914-445a-b049-1f61d236b376"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OG   \ttensor([3, 1, 5, 0, 0, 2, 3, 1, 3, 2])\n",
            "LABEL 0\ttensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
            "counts: \t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 254009.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18854, 3562, 0, 0, 0, 0]\n",
            "lens:  981 211 211\n",
            "\n",
            "LABEL 1\ttensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "counts: \t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 255541.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18768, 3648, 0, 0, 0, 0]\n",
            "lens:  981 211 211\n",
            "\n",
            "LABEL 2\ttensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1])\n",
            "counts: \t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 74963.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18729, 3687, 0, 0, 0, 0]\n",
            "lens:  981 211 211\n",
            "\n",
            "LABEL 3\ttensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
            "counts: \t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 259167.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18546, 3870, 0, 0, 0, 0]\n",
            "lens:  981 211 211\n",
            "\n",
            "LABEL 4\ttensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "counts: \t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 251452.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18594, 3822, 0, 0, 0, 0]\n",
            "lens:  981 211 211\n",
            "\n",
            "LABEL 5\ttensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
            "counts: \t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 421788.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18589, 3827, 0, 0, 0, 0]\n",
            "lens:  981 211 211\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation functions\n",
        "\n",
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "metadata": {
        "id": "D708PbeMPXme"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 class BERT\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "six_bert = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    num_labels = 6,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        "  ).to(device)\n",
        "\n",
        "model = six_bert\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                            lr = 5e-5,\n",
        "                            eps = 1e-08\n",
        "                            )\n",
        "lossFn = nn.CrossEntropyLoss().cuda()\n",
        "epochs = 2\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    updator=100\n",
        "    for step, batch in enumerate(six_class_train_dataloader):\n",
        "        if (step + 1) % 100 == 0:\n",
        "          print(\"Step: \", step)\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                            token_type_ids = None, \n",
        "                            attention_mask = b_input_mask, \n",
        "                            labels = b_labels)\n",
        "\n",
        "        # Backward pass\n",
        "        cntLoss = lossFn(train_output.logits, b_labels)\n",
        "        cntLoss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += cntLoss\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    all_labels = np.array([])\n",
        "    all_preds = np.array([])\n",
        "\n",
        "    for batch in six_class_validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        all_labels = np.append(all_labels, label_ids)\n",
        "        all_preds = np.append(all_preds, np.argmax(logits, axis = 1).flatten())\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n",
        "\n",
        "    from sklearn.metrics import classification_report   \n",
        "    print(classification_report(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4hreCeOVuZX",
        "outputId": "bb46e322-0ee5-4182-be29-af76c0b6c089"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step:  99\n",
            "Step:  199\n",
            "Step:  299\n",
            "Step:  399\n",
            "Step:  499\n",
            "Step:  599\n",
            "Step:  699\n",
            "Step:  799\n",
            "Step:  899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 1/2 [05:00<05:00, 300.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 1.2704\n",
            "\t - Validation Accuracy: 0.2085\n",
            "\t - Validation Precision: 0.4528\n",
            "\t - Validation Recall: 0.7583\n",
            "\t - Validation Specificity: 0.4603\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.64      0.71       540\n",
            "         1.0       0.46      0.65      0.54       541\n",
            "         2.0       0.62      0.40      0.48       573\n",
            "         3.0       0.43      0.65      0.52       569\n",
            "         4.0       0.43      0.34      0.38       537\n",
            "         5.0       0.88      0.73      0.80       602\n",
            "\n",
            "    accuracy                           0.57      3362\n",
            "   macro avg       0.60      0.57      0.57      3362\n",
            "weighted avg       0.60      0.57      0.57      3362\n",
            "\n",
            "Step:  99\n",
            "Step:  199\n",
            "Step:  299\n",
            "Step:  399\n",
            "Step:  499\n",
            "Step:  599\n",
            "Step:  699\n",
            "Step:  799\n",
            "Step:  899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 2/2 [10:00<00:00, 300.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.9491\n",
            "\t - Validation Accuracy: 0.1919\n",
            "\t - Validation Precision: 0.5562\n",
            "\t - Validation Recall: 0.8992\n",
            "\t - Validation Specificity: 0.6092\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.65      0.76       540\n",
            "         1.0       0.57      0.54      0.55       541\n",
            "         2.0       0.56      0.68      0.61       573\n",
            "         3.0       0.47      0.15      0.22       569\n",
            "         4.0       0.46      0.64      0.53       537\n",
            "         5.0       0.68      0.95      0.79       602\n",
            "\n",
            "    accuracy                           0.60      3362\n",
            "   macro avg       0.61      0.60      0.58      3362\n",
            "weighted avg       0.61      0.60      0.58      3362\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble BERT"
      ],
      "metadata": {
        "id": "8wNB8EqzRr6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define all models\n",
        "\n",
        "BERTs = []\n",
        "for i in range(numModels):\n",
        "  model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        "  )\n",
        "  model.cuda()\n",
        "\n",
        "  BERTs.append(model)"
      ],
      "metadata": {
        "id": "JyBOaMArQOVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train each BERT\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "print(\"Trainset length: \", len(train_dataloader))\n",
        "for bertNum in range(numModels):\n",
        "  print(\"TRAINING BERT #%d\" % bertNum)\n",
        "\n",
        "  train_dataloader = train_dataloaders[bertNum]\n",
        "  validation_dataloader = validation_dataloaders[bertNum]\n",
        "\n",
        "\n",
        "  print(train_dataloaders[bertNum])\n",
        "\n",
        "  model = BERTs[bertNum]\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                              lr = 5e-7,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "  classWeights = torch.tensor([1., 100.]).float().cuda()\n",
        "  print(classWeights)\n",
        "  lossFn = nn.CrossEntropyLoss(weight=classWeights)\n",
        "\n",
        "  for _ in trange(epochs, desc = 'Epoch'):\n",
        "      \n",
        "      # ========== Training ==========\n",
        "      \n",
        "      # Set model to training mode\n",
        "      model.train()\n",
        "      \n",
        "      # Tracking variables\n",
        "      tr_loss = 0\n",
        "      nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "      updator=100\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "          if (step + 1) % 100 == 0:\n",
        "            print(\"Step: \", step)\n",
        "\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          optimizer.zero_grad()\n",
        "          # Forward pass\n",
        "          train_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask, \n",
        "                              labels = b_labels)\n",
        "          # Backward pass\n",
        "          cntLoss = lossFn(train_output.logits, b_labels)\n",
        "          cntLoss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "          # Update tracking variables\n",
        "          tr_loss += cntLoss\n",
        "          nb_tr_examples += b_input_ids.size(0)\n",
        "          nb_tr_steps += 1\n",
        "\n",
        "      # ========== Validation ==========\n",
        "\n",
        "      # Set model to evaluation mode\n",
        "      model.eval()\n",
        "\n",
        "      # Tracking variables \n",
        "      val_accuracy = []\n",
        "      val_precision = []\n",
        "      val_recall = []\n",
        "      val_specificity = []\n",
        "\n",
        "      for batch in validation_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          with torch.no_grad():\n",
        "            # Forward pass\n",
        "            eval_output = model(b_input_ids, \n",
        "                                token_type_ids = None, \n",
        "                                attention_mask = b_input_mask)\n",
        "          logits = eval_output.logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "          # Calculate validation metrics\n",
        "          b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "          val_accuracy.append(b_accuracy)\n",
        "          # Update precision only when (tp + fp) !=0; ignore nan\n",
        "          if b_precision != 'nan': val_precision.append(b_precision)\n",
        "          # Update recall only when (tp + fn) !=0; ignore nan\n",
        "          if b_recall != 'nan': val_recall.append(b_recall)\n",
        "          # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "          if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "      print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "      print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "      print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "      print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "      print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "AuY1AL-XQpAm",
        "outputId": "74538cf0-c1c9-4006-fa28-2b6052096d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainset length:  981\n",
            "TRAINING BERT #0\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f217e3652a0>\n",
            "tensor([  1., 100.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step:  99\n",
            "Step:  199\n",
            "Step:  299\n",
            "Step:  399\n",
            "Step:  499\n",
            "Step:  599\n",
            "Step:  699\n",
            "Step:  799\n",
            "Step:  899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 1/2 [04:34<04:34, 274.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 2.0005\n",
            "\t - Validation Accuracy: 0.8320\n",
            "\t - Validation Precision: NaN\n",
            "\t - Validation Recall: 0.0000\n",
            "\t - Validation Specificity: 1.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 1/2 [04:47<04:47, 287.03s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-a0c935d416d8>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-a0c935d416d8>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical training\n",
        "\n",
        "BERT seems to learn how to classify classes 0 and 5 very well, but cant disstinguish between the rest.\n",
        "\n",
        "We will now try a hierarchical approach, first discriminating between (0,5 and not-0-or-5), and then training a separate model to further classify the not-0-or-5 entries into 1,2,3 and 4 "
      ],
      "metadata": {
        "id": "G2HfA4cOlN5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "tree so far:\n",
        "\n",
        "    ___\n",
        "   / | \\\n",
        "  0  5  else\n",
        "        -+-\n",
        "      / | | \\\n",
        "     1  2 3  4\n",
        "\n",
        "FIRST BRANCH:\n",
        "remapping \n",
        "1,2,3,4   -> 0\n",
        "0         -> 1\n",
        "5         -> 2\n",
        "\n",
        "\n",
        "SECOND BRANCH:\n",
        "remapping\n",
        "1         -> 0\n",
        "2         -> 1\n",
        "3         -> 2\n",
        "4         -> 3\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# convert labels to first branch mappings\n",
        "first_node_labels = torch.tensor(np.zeros_like(labels))\n",
        "first_node_labels[(labels == 0).nonzero()] = 1\n",
        "first_node_labels[(labels == 5).nonzero()] = 2\n",
        "\n",
        "\n",
        "first_node_train_set = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          first_node_labels[train_idx])\n",
        "\n",
        "first_node_val_set = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        first_node_labels[val_idx])\n",
        "\n",
        "first_node_test_set = TensorDataset(token_id[test_idx], \n",
        "                        attention_masks[test_idx], \n",
        "                        first_node_labels[test_idx])\n",
        "\n",
        "first_node_train_dataloader = DataLoader(\n",
        "            first_node_train_set,\n",
        "            sampler = RandomSampler(first_node_train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "first_node_validation_dataloader = DataLoader(\n",
        "            first_node_val_set,\n",
        "            sampler = SequentialSampler(first_node_val_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "first_node_test_dataloader = DataLoader(\n",
        "            first_node_test_set,\n",
        "            sampler = SequentialSampler(first_node_test_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "  \n",
        "print(\"first branch counts: \", end='\\t')\n",
        "counts = [0,0,0,0,0,0]\n",
        "for el in tqdm(first_node_labels):\n",
        "  counts[el] += 1\n",
        "print(counts)\n",
        "\n",
        "print(\"lens: \", len(first_node_train_dataloader), len(first_node_validation_dataloader), len(first_node_test_dataloader))\n",
        "print()\n",
        "\n",
        "\n",
        "# get only second node branch mappings\n",
        "# second_node_labels = labels[labels != 0]\n",
        "# second_node_labels = second_node_labels[second_node_labels != 5]\n",
        "\n",
        "# temp = np.copy(second_node_labels)\n",
        "# second_node_labels[(temp == 1).nonzero()] = 0\n",
        "# second_node_labels[(temp == 2).nonzero()] = 1\n",
        "# second_node_labels[(temp == 3).nonzero()] = 2\n",
        "# second_node_labels[(temp == 4).nonzero()] = 3\n",
        "\n",
        "second_node_labels = torch.tensor(np.copy(labels))\n",
        "second_node_labels[(labels == 0).nonzero()] = 9\n",
        "second_node_labels[(labels == 1).nonzero()] = 0\n",
        "second_node_labels[(labels == 2).nonzero()] = 1\n",
        "second_node_labels[(labels == 3).nonzero()] = 2\n",
        "second_node_labels[(labels == 4).nonzero()] = 3\n",
        "second_node_labels[(labels == 5).nonzero()] = 9\n",
        "\n",
        "second_node_labels = second_node_labels[second_node_labels != 9]\n",
        "\n",
        "# get second branch indices\n",
        "second_train_idx, second_temp_idx = train_test_split(\n",
        "    np.arange(len(second_node_labels)),\n",
        "    test_size = valntest_ratio,\n",
        "    shuffle = True,\n",
        "    stratify = second_node_labels)\n",
        "\n",
        "second_val_idx, second_test_idx = train_test_split(\n",
        "    np.arange(len(second_node_labels[second_temp_idx])),\n",
        "    test_size = valtest_split,\n",
        "    shuffle = True,\n",
        "    stratify = second_node_labels[second_temp_idx])\n",
        "\n",
        "\n",
        "second_node_train_set = TensorDataset(token_id[second_train_idx], \n",
        "                          attention_masks[second_train_idx], \n",
        "                          second_node_labels[second_train_idx])\n",
        "\n",
        "second_node_val_set = TensorDataset(token_id[second_val_idx], \n",
        "                        attention_masks[second_val_idx], \n",
        "                        second_node_labels[second_val_idx])\n",
        "\n",
        "second_node_test_set = TensorDataset(token_id[second_test_idx], \n",
        "                        attention_masks[second_test_idx], \n",
        "                        second_node_labels[second_test_idx])\n",
        "\n",
        "second_node_train_dataloader = DataLoader(\n",
        "            second_node_train_set,\n",
        "            sampler = RandomSampler(second_node_train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "second_node_validation_dataloader = DataLoader(\n",
        "            second_node_val_set,\n",
        "            sampler = SequentialSampler(second_node_val_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "second_node_test_dataloader = DataLoader(\n",
        "            second_node_test_set,\n",
        "            sampler = SequentialSampler(second_node_test_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "print(labels)\n",
        "print(first_node_labels)\n",
        "print(second_node_labels)\n",
        "\n",
        "for i in range(0,50):\n",
        "  print(int(labels[i]), end=' ')\n",
        "\n",
        "print()\n",
        "\n",
        "for i in range(0,50):\n",
        "  print(int(second_node_labels[i]), end=' ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXKWuaPDlyfI",
        "outputId": "de735b84-b162-48bf-ee64-2f4bcfcfad1c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first branch counts: \t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22416/22416 [00:00<00:00, 68757.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15027, 3562, 3827, 0, 0, 0]\n",
            "lens:  981 211 211\n",
            "\n",
            "tensor([5, 1, 2,  ..., 3, 2, 4])\n",
            "tensor([2, 0, 0,  ..., 0, 0, 0])\n",
            "tensor([0, 1, 0,  ..., 2, 1, 3])\n",
            "5 1 2 1 3 2 0 3 5 1 2 4 0 4 1 5 3 3 1 4 3 4 2 3 5 4 3 2 3 0 2 3 1 0 4 2 2 5 3 3 5 5 3 3 4 0 4 3 5 4 \n",
            "0 1 0 2 1 2 0 1 3 3 0 2 2 0 3 2 3 1 2 3 2 1 2 1 2 0 3 1 1 2 2 2 2 3 3 2 3 2 3 2 1 1 2 2 2 0 3 3 3 1 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = [0,0,0,0]\n",
        "for k in second_node_train_dataloader:\n",
        "  for e in k[-1]:\n",
        "    counts[e] += 1\n",
        "\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE-iNSIJzqrM",
        "outputId": "4732de28-86e5-47b6-bc18-3cbba1d34545"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2553, 2581, 2709, 2675]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train both BERTs on each dataset separately\n",
        "# during inference, things that first_node_bert classifies as '0' are sent to second_node_bert for further classification\n",
        "# training occurs separately\n",
        "\n",
        "# train first bert\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "first_node_bert = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    num_labels = 3,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        "  ).to(device)\n",
        "\n",
        "model = first_node_bert\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                            lr = 5e-5,\n",
        "                            eps = 1e-08\n",
        "                            )\n",
        "lossFn = nn.CrossEntropyLoss().cuda()\n",
        "epochs = 2\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    updator=100\n",
        "    for step, batch in enumerate(first_node_train_dataloader):\n",
        "        if (step + 1) % 100 == 0:\n",
        "          print(\"Step: \", step)\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                            token_type_ids = None, \n",
        "                            attention_mask = b_input_mask, \n",
        "                            labels = b_labels)\n",
        "\n",
        "        # Backward pass\n",
        "        cntLoss = lossFn(train_output.logits, b_labels)\n",
        "        cntLoss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += cntLoss\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    all_labels = np.array([])\n",
        "    all_preds = np.array([])\n",
        "\n",
        "    for batch in first_node_validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        all_labels = np.append(all_labels, label_ids)\n",
        "        all_preds = np.append(all_preds, np.argmax(logits, axis = 1).flatten())\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n",
        "\n",
        "    from sklearn.metrics import classification_report   \n",
        "    print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJZwPzdPqmzb",
        "outputId": "5dfdc73d-a3b5-49a7-8c33-c945c40cdead"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step:  99\n",
            "Step:  199\n",
            "Step:  299\n",
            "Step:  399\n",
            "Step:  499\n",
            "Step:  599\n",
            "Step:  699\n",
            "Step:  799\n",
            "Step:  899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 1/2 [04:46<04:46, 286.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.5838\n",
            "\t - Validation Accuracy: 0.7068\n",
            "\t - Validation Precision: 0.7633\n",
            "\t - Validation Recall: 0.5136\n",
            "\t - Validation Specificity: 0.9480\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.92      0.89      2220\n",
            "         1.0       0.76      0.64      0.69       540\n",
            "         2.0       0.85      0.76      0.80       602\n",
            "\n",
            "    accuracy                           0.84      3362\n",
            "   macro avg       0.82      0.77      0.79      3362\n",
            "weighted avg       0.84      0.84      0.84      3362\n",
            "\n",
            "Step:  99\n",
            "Step:  199\n",
            "Step:  299\n",
            "Step:  399\n",
            "Step:  499\n",
            "Step:  599\n",
            "Step:  699\n",
            "Step:  799\n",
            "Step:  899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 2/2 [09:46<00:00, 293.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.3642\n",
            "\t - Validation Accuracy: 0.7453\n",
            "\t - Validation Precision: 0.9334\n",
            "\t - Validation Recall: 0.5089\n",
            "\t - Validation Specificity: 0.9898\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.98      0.92      2220\n",
            "         1.0       0.94      0.62      0.74       540\n",
            "         2.0       0.94      0.80      0.87       602\n",
            "\n",
            "    accuracy                           0.89      3362\n",
            "   macro avg       0.92      0.80      0.84      3362\n",
            "weighted avg       0.89      0.89      0.88      3362\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train second bert\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "second_node_bert = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    num_labels = 4,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        "  ).to(device)\n",
        "\n",
        "model = second_node_bert\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                            lr = 1e-5,\n",
        "                            eps = 1e-08\n",
        "                            )\n",
        "lossFn = nn.CrossEntropyLoss().cuda()\n",
        "epochs = 2\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    updator=100\n",
        "    for step, batch in enumerate(second_node_train_dataloader):\n",
        "        if (step + 1) % 100 == 0:\n",
        "          print(\"Step: \", step)\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                            token_type_ids = None, \n",
        "                            attention_mask = b_input_mask, \n",
        "                            labels = b_labels)\n",
        "\n",
        "        # Backward pass\n",
        "        cntLoss = lossFn(train_output.logits, b_labels)\n",
        "        cntLoss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += cntLoss\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    all_labels = np.array([])\n",
        "    all_preds = np.array([])\n",
        "\n",
        "    for batch in second_node_validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        all_labels = np.append(all_labels, label_ids)\n",
        "        all_preds = np.append(all_preds, np.argmax(logits, axis = 1).flatten())\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n",
        "\n",
        "    from sklearn.metrics import classification_report   \n",
        "    print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yqnjtQ2vqJU",
        "outputId": "459682bb-5d7b-49ad-8d6c-a93794f7db26"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step:  99\n",
            "Step:  199\n",
            "Step:  299\n",
            "Step:  399\n",
            "Step:  499\n",
            "Step:  599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\rEpoch:  50%|█████     | 1/2 [03:21<03:21, 201.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 1.3972\n",
            "\t - Validation Accuracy: 0.0009\n",
            "\t - Validation Precision: 0.1667\n",
            "\t - Validation Recall: 1.0000\n",
            "\t - Validation Specificity: 0.0000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       567\n",
            "         1.0       0.17      0.00      0.01       549\n",
            "         2.0       0.26      0.81      0.40       575\n",
            "         3.0       0.26      0.22      0.24       563\n",
            "\n",
            "    accuracy                           0.26      2254\n",
            "   macro avg       0.17      0.26      0.16      2254\n",
            "weighted avg       0.17      0.26      0.16      2254\n",
            "\n",
            "Step:  99\n",
            "Step:  199\n",
            "Step:  299\n",
            "Step:  399\n",
            "Step:  499\n",
            "Step:  599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 2/2 [06:42<00:00, 201.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 1.3883\n",
            "\t - Validation Accuracy: 0.1550\n",
            "\t - Validation Precision: 0.3999\n",
            "\t - Validation Recall: 0.1225\n",
            "\t - Validation Specificity: 0.6492\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.46      0.35       567\n",
            "         1.0       0.37      0.17      0.23       549\n",
            "         2.0       0.30      0.54      0.38       575\n",
            "         3.0       0.32      0.05      0.08       563\n",
            "\n",
            "    accuracy                           0.30      2254\n",
            "   macro avg       0.32      0.30      0.26      2254\n",
            "weighted avg       0.32      0.30      0.26      2254\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in trange(2, 4, desc = 'Epoch'):\n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    updator=100\n",
        "    for step, batch in enumerate(second_node_train_dataloader):\n",
        "        if (step + 1) % 100 == 0:\n",
        "          print(\"Step: \", step)\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                            token_type_ids = None, \n",
        "                            attention_mask = b_input_mask, \n",
        "                            labels = b_labels)\n",
        "\n",
        "        # Backward pass\n",
        "        cntLoss = lossFn(train_output.logits, b_labels)\n",
        "        cntLoss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += cntLoss\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    all_labels = np.array([])\n",
        "    all_preds = np.array([])\n",
        "\n",
        "    for batch in second_node_validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        all_labels = np.append(all_labels, label_ids)\n",
        "        all_preds = np.append(all_preds, np.argmax(logits, axis = 1).flatten())\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n",
        "\n",
        "    from sklearn.metrics import classification_report   \n",
        "    print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKZsi7OxDX2R",
        "outputId": "f150b660-a422-477e-a6d8-27d6ecfa7852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step:  99\n"
          ]
        }
      ]
    }
  ]
}